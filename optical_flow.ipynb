{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2867,
     "status": "ok",
     "timestamp": 1701097026277,
     "user": {
      "displayName": "­문희준 | 인공지능학과 | 한양대(서울)",
      "userId": "12627775913057364184"
     },
     "user_tz": -540
    },
    "id": "yAKXA7Z7Gwz0",
    "outputId": "612196d8-1366-4650-c628-3ad957a2bf19"
   },
   "outputs": [],
   "source": [
    "isColab = False\n",
    "\n",
    "if(isColab):\n",
    "    # connect google drive\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4IAMDrBMnClu"
   },
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lrjtVs-oGODv"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "if(isColab): from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHVW6Ht3nE_L"
   },
   "source": [
    "# Part1: goodFeaturesToTrack\n",
    "- Fill the missing part (denoted as ```fill here```) of the code\n",
    "- We provide procedure comments for complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_box_filter(image, kernel_size):\n",
    "    # Pad the image with zeros to handle border cases\n",
    "    pad_size = kernel_size // 2\n",
    "    if len(image.shape) == 3:\n",
    "        padded_image = np.pad(image, ((pad_size, pad_size), (pad_size, pad_size), (0, 0)), 'constant')\n",
    "    else:\n",
    "        padded_image = np.pad(image, pad_size, 'constant')\n",
    "\n",
    "    # Compute the integral image\n",
    "    integral_img = np.cumsum(np.cumsum(padded_image, axis=0), axis=1)\n",
    "\n",
    "    # Compute the sums using the integral image\n",
    "    sum_top_right = integral_img[kernel_size:, kernel_size:]\n",
    "    sum_top_left = integral_img[kernel_size:, :-kernel_size]\n",
    "    sum_bottom_right = integral_img[:-kernel_size, kernel_size:]\n",
    "    sum_bottom_left = integral_img[:-kernel_size, :-kernel_size]\n",
    "\n",
    "    sums = sum_top_right - sum_top_left - sum_bottom_right + sum_bottom_left\n",
    "\n",
    "    # Divide by kernel area to get the average\n",
    "    filtered_image = sums / (kernel_size ** 2)\n",
    "\n",
    "    # Crop the filtered image to the original size\n",
    "    return filtered_image[pad_size:-pad_size, pad_size:-pad_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_blur(image, kernel_size):\n",
    "    if len(image.shape) == 2:  # Grayscale image\n",
    "        rows, cols = image.shape\n",
    "        image_blurred = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                start_row, end_row = max(0, i - kernel_size // 2), min(rows, i + kernel_size // 2 + 1)\n",
    "                start_col, end_col = max(0, j - kernel_size // 2), min(cols, j + kernel_size // 2 + 1)\n",
    "                image_blurred[i, j] = np.mean(image[start_row:end_row, start_col:end_col])\n",
    "\n",
    "    elif len(image.shape) == 3:  # RGB image\n",
    "        rows, cols, channels = image.shape\n",
    "        image_blurred = np.zeros_like(image, dtype=np.float32)\n",
    "\n",
    "        for c in range(channels):\n",
    "            for i in range(rows):\n",
    "                for j in range(cols):\n",
    "                    start_row, end_row = max(0, i - kernel_size // 2), min(rows, i + kernel_size // 2 + 1)\n",
    "                    start_col, end_col = max(0, j - kernel_size // 2), min(cols, j + kernel_size // 2 + 1)\n",
    "                    image_blurred[i, j, c] = np.mean(image[start_row:end_row, start_col:end_col, c])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported image shape\")\n",
    "\n",
    "    return image_blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "AEPUBxp_GPpl"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def goodFeaturesToTrack(image, maxCorners=100, qualityLevel=0.03, blocksize=7):\n",
    "    \n",
    "    # Image blurring with averaging filter\n",
    "    image = custom_blur(image, blocksize)\n",
    "    \n",
    "    # Compute gradients using Sobel filter\n",
    "    Ix = np.gradient(image, axis=1)\n",
    "    Iy = np.gradient(image, axis=0)\n",
    "    \n",
    "    # Compute products of gradients at each pixel\n",
    "    Ixx = Ix**2\n",
    "    Iyy = Iy**2\n",
    "    Ixy = Ix*Iy\n",
    "    \n",
    "    # Compute the sums of products of gradients in local windows\n",
    "    Sxx = custom_box_filter(Ixx, blocksize)\n",
    "    Syy = custom_box_filter(Iyy, blocksize)\n",
    "    Sxy = custom_box_filter(Ixy, blocksize)\n",
    "\n",
    "    # Compute the determinant and trace of the matrix M for each pixel\n",
    "    detM = (Sxx * Syy) - (Sxy**2)\n",
    "    traceM = Sxx + Syy\n",
    "    \n",
    "    # Compute the Harris response with detM and traceM\n",
    "    harris_response = detM - 0.04 * (traceM**2)\n",
    "    \n",
    "    # Threshold the Harris response to find candidate corners\n",
    "    threshold = qualityLevel * harris_response.max()\n",
    "    corners = np.argwhere(harris_response > threshold)\n",
    "    \n",
    "    # Sort the corners by Harris response in descending order\n",
    "    sorted_corners = corners[np.argsort(harris_response[corners[:, 0], corners[:, 1]])[::-1]]\n",
    "    \n",
    "    # Keep the top 'maxCorners' corners\n",
    "    selected_corners = sorted_corners[:maxCorners]\n",
    "\n",
    "    final_corners = np.array(selected_corners)\n",
    "    final_corners = final_corners.reshape(-1, 1, 2)\n",
    "\n",
    "    return final_corners\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gcb42xzntML"
   },
   "source": [
    "# Part2: Optical flow with Lukas-Kanade\n",
    "- Fill the missing part (denoted as ```fill here```) of the code\n",
    "- We provide procedure comments for complete the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lv7zvb_nG8ql"
   },
   "outputs": [],
   "source": [
    "\n",
    "def optical_flow(old_frame, new_frame, window_size, min_quality):\n",
    "\n",
    "    feature_list = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n",
    "\n",
    "    w = int(window_size/2)\n",
    "\n",
    "    # Normalize\n",
    "    old_frame = old_frame / 255.0\n",
    "    new_frame = new_frame / 255.0\n",
    "\n",
    "    # Convolve to get gradients w.r.to X, Y and T dimensions\n",
    "    kernel_x = np.array([[-1, 1], [-1, 1]]) * 0.25  # Sobel kernel for x-gradient\n",
    "    kernel_y = np.array([[-1, -1], [1, 1]]) * 0.25  # Sobel kernel for y-gradient\n",
    "    kernel_t = np.array([[1, 1], [1, 1]]) * 0.25  # Simple difference kernel for t-gradient\n",
    "\n",
    "\n",
    "    # cv2.filter2D is allowed for convolution!\n",
    "    fx = cv2.filter2D(old_frame, -1, kernel_x)\n",
    "    fy = cv2.filter2D(old_frame, -1, kernel_y)\n",
    "    ft = cv2.filter2D(new_frame, -1, kernel_t) - cv2.filter2D(old_frame, -1, kernel_t)\n",
    "\n",
    "    u = np.zeros(old_frame.shape)\n",
    "    v = np.zeros(old_frame.shape)\n",
    "\n",
    "    for feature in feature_list:\n",
    "        i, j = feature.ravel()\n",
    "        i, j = int(i), int(j)\n",
    "\n",
    "        Ix = fx[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "        Iy = fy[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "        It = ft[i-w:i+w+1, j-w:j+w+1].flatten()\n",
    "\n",
    "        b = -It  # Negate It to move it to the right-hand side of the equation\n",
    "        A = np.vstack((Ix, Iy)).T\n",
    "\n",
    "        # Add a regularization term to A.T @ A for numerical stability\n",
    "        nu = 0.001\n",
    "        U = np.linalg.pinv(A.T @ A + nu * np.eye(2)) @ A.T @ b\n",
    "\n",
    "        u[i, j] = U[0]\n",
    "        v[i, j] = U[1]\n",
    "\n",
    "    return (u, v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4N4xHKEHAjA"
   },
   "source": [
    "# Main function\n",
    "- If part1 and part2 were filled properly, the 'output.avi' will be generated!\n",
    "- For google colab, as cv2.imshow() is not provided, so please use cv2_imshow (google.colab.patches) instead  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1jc3BhjKfDZfJ321WXMvukBMVD4RLX7_X"
    },
    "id": "APQHNcblG_Jp",
    "outputId": "1191d4ce-4a66-46ac-d50b-d2a54b97a83e"
   },
   "outputs": [],
   "source": [
    "if(isColab): cap = cv2.VideoCapture('/content/drive/MyDrive/optical_flow/slow.mp4')\n",
    "else: cap = cv2.VideoCapture(\"C:/Users/labinno/Desktop/cv_project/slow.mp4\")\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "\n",
    "# Width and height of the file to save\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# 'output.mp4' will be generated!\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('output.avi', fourcc, 30.0, (int(width), int(height)))\n",
    "\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Shi Tomasi parameter\n",
    "max_corners = 100\n",
    "min_quality = 0.3\n",
    "blocksize = 7\n",
    "p0 = goodFeaturesToTrack(old_frame, max_corners, min_quality, blocksize)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "    ret, current_frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    U, V = optical_flow(old_gray, frame_gray, 15, 0.03)\n",
    "\n",
    "    for i in range(current_frame.shape[0]):\n",
    "        for j in range(current_frame.shape[1]):\n",
    "            u, v = U[i][j], V[i][j]\n",
    "            if u and v:\n",
    "                mask = cv2.line(mask, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), 2)\n",
    "                frame = cv2.arrowedLine(current_frame, (j, i), (int(round(j + u)), int(round(i + v))), (0, 255, 0), thickness=2)\n",
    "                current_frame = cv2.add(current_frame, mask)\n",
    "\n",
    "    # Display the frame with optical flow vectors\n",
    "    if(isColab): cv2_imshow(current_frame)  # For Google Colab\n",
    "    else: cv2.imshow('Lucas-Kanade Optical Flow', current_frame)\n",
    "    \n",
    "    out.write(current_frame)\n",
    "    # Break the loop if 'Esc' key is pressed\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break\n",
    "\n",
    "    # Set the current frame as the previous frame for the next iteration\n",
    "    old_gray = frame_gray\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "# Close the plot window when done\n",
    "plt.close()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OTF_2ulyHPJF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPmSnLvV7ASB4989omnVNL2",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
